from RL.vf_TR_class import value_function_TR
from common.rl_utils import load_rl_params
from common.utils import load_env_params
import datetime, copy
import torch
import argparse
import wandb

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Train a value function using the trajectories generated by an agent')
    parser.add_argument('--project', type=str, help='Path to the model to be used for generating data points and trajectories')
    parser.add_argument('--env_id', type=str, help='Name of the environment to be used for generating data points and trajectories')
    parser.add_argument('--algorithm', type=str, help='Name of the RL algorithm to be loaded')
    parser.add_argument('--model_name', type=str, help='Path to the model to be used for generating data points and trajectories')
    parser.add_argument("--mode", type=str, choices=['deterministic', 'stochastic'], required=True)
    parser.add_argument("--uncertainty_value", type=float, help="List of uncertainty scale values")
    args = parser.parse_args()
    # Load model and environment
    path = f"train_data/{args.project}/{args.algorithm}"
    # wandb.init(config=args)

    model_path = f"{path}/{args.mode}/models/{args.model_name}/best_model.zip"
    env_path = f"{path}/{args.mode}/envs/{args.model_name}/best_vecnormalize.pkl"

    assert args.mode in ['deterministic', 'stochastic'], "Mode must be either 'deterministic' or 'stochastic'"
    if args.mode == 'stochastic':
        assert args.uncertainty_value is not None, "Uncertainty scale must be provided for stochastic mode"
        assert (0 < args.uncertainty_value < 1), "Uncertainty scale values must be between 0 and 1"
    else:
        args.uncertainty_value = 0


    env_params = load_env_params(args.env_id)
    env_params["uncertainty_value"] = args.uncertainty_value
    hyperparameters, rl_env_params = load_rl_params(args.env_id, args.algorithm)
    env_params.update(rl_env_params)
    L = env_params["n_days"]*86400
    N = int(L//env_params["dt"])

    # Create value function
    my_value_function = value_function_TR(
        input_dim=2,
        hidden_dim=128,
        learning_rate=1e-3,
        batch_size=128,
        reduced= True
    )

    # Generate data points and trajectories using the specified model and environment
    data_points, trajectories = my_value_function.sim_with_agent(
        env_params=env_params,
        num_traj=10,
        spread=0.5,
        model_path=model_path, 
        env_path=env_path, 
        stochastic=args.mode,
    )

    config = {
        "input_dim": 2,
        "hidden_dim": 128,
        "learning_rate": 1e-3,
        "batch_size": 128,
        "reduced": True
    }

    run = wandb.init(
        project=args.project,
        config=config,
        group=f"vf_{args.algorithm}_{args.model_name}",
        sync_tensorboard=True,
        config_exclude_keys=[],
        # save_code=save_code,
        allow_val_change=True,
    )


    # WHY IS THE VALUE FUNCTION CREATED AGAIN OVERHERE?
    my_vf = value_function_TR(
        input_dim=2,
        hidden_dim=128,
        learning_rate=1e-3,
        batch_size=1024,
        reduced= True,
        wandb_run=run,
        N=N,
    )
    # wandb.watch(my_vf.neural_net, log_freq=1)
    print(f"Network device: {next(my_vf.neural_net.parameters()).device}")
    if torch.cuda.is_available():
        my_vf.neural_net.to('cuda')
        # my_vf.input_tensor = my_vf.input_tensor.cuda()
        # my_vf.target_tensor = my_vf.target_tensor.cuda()

    my_vf.values  = copy.deepcopy(my_value_function.values)
    my_vf.trajectories = copy.deepcopy(my_value_function.trajectories)
    my_vf.train(epochs=200)

    # Create folders for export
    # current_day_time = datetime.datetime.now().strftime("%Y%m%d_%H%M")
    # save_path = f"train_data/{args.project}/{args.algorithm}/{args.mode}/models/{args.model_name}/vf.zip"
    # torch.save(my_vf.neural_net, save_path)
