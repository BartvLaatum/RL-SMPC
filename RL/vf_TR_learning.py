from RL.vf_TR_class import value_function_TR
from common.rl_utils import load_rl_params
from common.utils import load_env_params
import datetime, copy
import torch
import argparse
import wandb

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Train a value function using the trajectories generated by an agent')
    parser.add_argument('--project', type=str, help='Path to the model to be used for generating data points and trajectories')
    parser.add_argument('--model_name', type=str, help='Path to the model to be used for generating data points and trajectories')
    parser.add_argument('--env_id', type=str, help='Name of the environment to be used for generating data points and trajectories')
    parser.add_argument('--algorithm', type=str, help='Name of the RL algorithm to be loaded')
    parser.add_argument('--stochastic', action='store_true', help='Flag to indicate if the simulation should be stochastic')
    args = parser.parse_args()
    # Load model and environment
    path = f"train_data/{args.project}/{args.algorithm}"
    # wandb.init(config=args)

    if args.stochastic:
        model_path = f"{path}/stochastic/models/{args.model_name}/best_model.zip"
        env_path = f"{path}/stochastic/envs/{args.model_name}/best_vecnormalize.pkl"
    else:
        model_path = f"{path}/deterministic/models/{args.model_name}/best_model.zip"
        env_path = f"{path}/deterministic/envs/{args.model_name}/best_vecnormalize.pkl"

    env_params = load_env_params(args.env_id)
    hyperparameters, rl_env_params = load_rl_params(args.env_id, args.algorithm)
    env_params.update(rl_env_params)

    # Create value function
    my_value_function = value_function_TR(
        input_dim=2,
        hidden_dim=128,
        learning_rate=1e-3,
        batch_size=128,
        reduced= True
    )
    print(args.stochastic)
    # Generate data points and trajectories using the specified model and environment
    data_points, trajectories = my_value_function.sim_with_agent(
        env_params=env_params,
        num_traj=1000,
        spread=0.5,
        model_path=model_path, 
        env_path=env_path, 
        stochastic=args.stochastic,
    )

    config = {
        "input_dim": 2,
        "hidden_dim": 128,
        "learning_rate": 1e-3,
        "batch_size": 128,
        "reduced": True
    }

    run = wandb.init(
        project=args.project,
        config=config,
        group=f"vf_{args.algorithm}_{args.model_name}",
        sync_tensorboard=True,
        config_exclude_keys=[],
        # save_code=save_code,
        allow_val_change=True,
    )


    # WHY IS THE VALUE FUNCTION CREATED AGAIN OVERHERE?
    my_vf = value_function_TR(
        input_dim=2,
        hidden_dim=128,
        learning_rate=1e-3,
        batch_size=1024,
        reduced= True,
        wandb_run=run
    )
    wandb.watch(my_vf.neural_net, log_freq=1)

    my_vf.values  = copy.deepcopy(my_value_function.values)
    my_vf.trajectories = copy.deepcopy(my_value_function.trajectories)
    my_vf.train(epochs=200)

    # Save the value function
    # Import arguments
    # if len(sys.argv) > 1:
    #     T = int(sys.argv[1])
    #     job_desc = "rlmpc_" + str(T) + "hr"
    #     job_id = sys.argv[2]
    # else:
    #     T = 1
    #     job_desc = "None"
    #     job_id = "0"
    #     print("No arguments provided, using default values")
    # print(f"Time horizon: {T} hours")
    # print(f"Job description: {job_desc}")

    # Create folders for export
    # current_day_time = datetime.datetime.now().strftime("%Y%m%d_%H%M")
    if args.stochastic:
        save_path = f"train_data/{args.project}/{args.algorithm}/stochastic/models/{args.model_name}/vf.zip"
    else:
        save_path = f"train_data/{args.project}/{args.algorithm}/deterministic/models/{args.model_name}/vf.zip"
    torch.save(my_vf.neural_net, save_path)
